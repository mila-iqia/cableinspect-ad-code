{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2024 Mila - Institut québécois d'intelligence artificielle\n",
    "# SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43864ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook permits to visualize for a given run the anomaly score predictions\n",
    "# and their statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc83c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import combinations\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils import compute_metrics, plot_confusion_matrix, plot_histogram, plot_precision_recall_curve, plot_roc_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To adapt\n",
    "root_directory = os.path.join(os.environ[\"HOME\"])\n",
    "experiment_name = \"hq_kfold_unsupervised_C01\"\n",
    "run_name = \"run.2024-05-27_11-25-44\"\n",
    "data_folder = os.path.join(root_directory, \"CableInspect-AD\")\n",
    "exp_folder = os.path.join(root_directory, f\"results/patchcore/hq/{experiment_name}/{run_name}\")\n",
    "\n",
    "cable_side_pass = \"C01\"  # Only used for HQ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file\n",
    "config_path = os.path.join(exp_folder, \"config.yaml\")\n",
    "config = OmegaConf.load(config_path)\n",
    "dataset = config.dataset.format\n",
    "print(f\"Dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66637461",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Split config:\\n  {config.dataset.split_mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predictions and metrics\n",
    "val_img_pred_file_name = os.path.join(exp_folder, \"validation_image_predictions.csv\")\n",
    "test_img_pred_file_name = os.path.join(exp_folder, \"test_image_predictions.csv\")\n",
    "normalization_file_name = os.path.join(exp_folder, \"normalization_stats.csv\")\n",
    "metrics_file_name = os.path.join(exp_folder, \"logs\", \"lightning_logs\", \"version_0\", \"metrics.csv\")\n",
    "\n",
    "df_val = pd.read_csv(val_img_pred_file_name)\n",
    "df_test = pd.read_csv(test_img_pred_file_name)\n",
    "\n",
    "stats = pd.read_csv(normalization_file_name)\n",
    "metrics = pd.read_csv(metrics_file_name)[-2:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084414a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_threshold = stats[\"image_threshold\"].values[0].round(2)\n",
    "metrics_lst = [\"F1Score\", \"Precision\", \"Recall\", \"AUPR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4c35e-4617-4478-b21f-782465796329",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = {\n",
    "    \"nominal\": \"tab:blue\",\n",
    "    \"anomalous\": \"tab:orange\",\n",
    "    \"bent strand important\": plt.cm.tab20(2),\n",
    "    \"bent strand light\": plt.cm.tab20(3),\n",
    "    \"broken strands complete\": plt.cm.tab20c(8),\n",
    "    \"broken strands extracted\": plt.cm.tab20c(10),\n",
    "    \"broken strands partial\": plt.cm.tab20c(11),\n",
    "    \"crushed important\": plt.cm.tab20(6),\n",
    "    \"crushed light\": plt.cm.tab20(7),\n",
    "    \"deposit important\": plt.cm.tab20(8),\n",
    "    \"deposit light\": plt.cm.tab20(9),\n",
    "    \"long scratches important\": plt.cm.tab20(10),\n",
    "    \"long scratches light\": plt.cm.tab20(11),\n",
    "    \"spaced strands important\": plt.cm.tab20(12),\n",
    "    \"spaced strands light\": plt.cm.tab20(13),\n",
    "    \"welded strands deep\": plt.cm.tab20c(16),\n",
    "    \"welded strands partial\": plt.cm.tab20c(18),\n",
    "    \"welded strands superficial\": plt.cm.tab20c(19),\n",
    "}\n",
    "\n",
    "# Plot colormap\n",
    "colors = [colormap[k] for k in sorted(colormap.keys()) if k not in [\"nominal\", \"anomalous\"]]\n",
    "labels = [k for k in sorted(colormap.keys()) if k not in [\"nominal\", \"anomalous\"]]\n",
    "norm = matplotlib.colors.BoundaryNorm(np.arange(1, 8) - 0.5, len(colors))\n",
    "x = np.arange(1, 17)\n",
    "cmap = matplotlib.colors.ListedColormap(colors)\n",
    "sc = plt.scatter(x, x, c=x, s=100, cmap=cmap)\n",
    "cbar = plt.colorbar(sc, ticks=x)\n",
    "cbar.ax.set_yticklabels(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144c0c2",
   "metadata": {},
   "source": [
    "# Per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b49fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define split to visualize\n",
    "split = \"test\"  # \"validation\"\n",
    "normalized = False\n",
    "\n",
    "if split == \"validation\":\n",
    "    df = df_val\n",
    "elif split == \"test\":\n",
    "    df = df_test\n",
    "else:\n",
    "    raise ValueError(\"split should be validation or test.\")\n",
    "\n",
    "if normalized:\n",
    "    prefix_scores = \"normalize_\"\n",
    "    threshold = 0.5\n",
    "    title = f\"Image {split} normalized anomaly scores\"\n",
    "else:\n",
    "    prefix_scores = \"\"\n",
    "    threshold = image_threshold\n",
    "    title = f\"Image {split} anomaly scores\"\n",
    "\n",
    "if dataset == \"hq\":\n",
    "    df = df[df[\"image_path\"].str.contains(cable_side_pass)]\n",
    "\n",
    "# Get labels\n",
    "if list(df[\"target\"].unique()) == [0]:\n",
    "    # Case where validation set contains only nominal images\n",
    "    # Note that in that case the end of the notebook will fail\n",
    "    # which is normal since their is no anomalous samples to analyze\n",
    "    label_groups = [\"nominal\"]\n",
    "else:\n",
    "    label_groups = [\"nominal\", \"anomalous\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f25b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the anomaly score distribution of the split\n",
    "groups = df.groupby([\"target\"])[f\"{prefix_scores}anomaly_score\"].apply(list).tolist()\n",
    "\n",
    "# Define bins for histogram (may need to be readjusted according to the runs)\n",
    "min_score = df[f\"{prefix_scores}anomaly_score\"].min()\n",
    "max_score = df[f\"{prefix_scores}anomaly_score\"].max()\n",
    "bin_range = int(max_score + 0.5) - int(min_score - 0.5) + 1\n",
    "bin_width = 1\n",
    "if bin_range > 15:\n",
    "    bin_width = bin_range // 15\n",
    "bins = [i for i in range(int(min_score - 0.5), int(max_score + 0.5) + bin_width + 1, bin_width)]\n",
    "\n",
    "# Legend title\n",
    "metric_prefix = f\"{split}_image_\"\n",
    "metrics_list_ = [\"Precision\", \"Recall\"]\n",
    "metrics_ = metrics[[f\"{metric_prefix}{m}\" for m in metrics_list_]].tolist()\n",
    "if len(label_groups) > 1:\n",
    "    legend_title = \"\\n\".join([f\"{k}: {v:0.2f}\" for k, v in zip(metrics_list_, metrics_)])\n",
    "else:\n",
    "    # Case where validation set contains only nominal images\n",
    "    legend_title = \"\"\n",
    "\n",
    "# Keep title outside of the plot for the report\n",
    "print(title)\n",
    "print(f\"Anomaly score: min = {min_score:0.2f}, max = {max_score:0.2f}\")\n",
    "plot_histogram(bins, groups, label_groups, threshold, legend_title, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5877d62-db7a-4cf5-978a-226f75d004af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"anomalous\" not in label_groups:\n",
    "    print(\"WARNING: The rest of the notebook should not be run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "predicted = df[f\"{prefix_scores}anomaly_score\"].to_numpy()\n",
    "actual = df[\"target\"].to_numpy()\n",
    "plot_confusion_matrix(np.where(predicted >= threshold, 1, 0), actual, label_groups, title, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46359335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Precision-Recall curve (image level)\n",
    "plot_precision_recall_curve(\n",
    "    actual,\n",
    "    predicted,\n",
    "    None,\n",
    "    None,\n",
    "    threshold,\n",
    "    recall_level=\"image\",\n",
    "    precision_level=\"image\",\n",
    "    title=\"\",  # f\"{split.capitalize()} set\\nPrecision-Recall curve\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13960e-aadb-4746-a4dd-2b200f699c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve\n",
    "plot_roc_curve(\n",
    "    actual,\n",
    "    predicted,\n",
    "    threshold,\n",
    "    title=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ba8bd",
   "metadata": {},
   "source": [
    "## Per anomaly type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc59a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract anomaly types\n",
    "# Extract anomaly types with grades\n",
    "# Note that multiple anomalies can happen in the same image.\n",
    "# For those cases the score will be duplicated so that each type of anomaly is represented in the figure.\n",
    "# Other possible option: for a given image keep the annotation for the more pronounced anomaly.\n",
    "labels = pd.read_csv(os.path.join(data_folder, \"labels.csv\"))\n",
    "labels[\"anomaly_types\"] = labels[\"anomaly_type\"].fillna(\"good\") + \" \" + labels[\"anomaly_grade\"].fillna(\"\")\n",
    "labels[\"anomaly_types\"].replace(\"good \", \"good\", inplace=True)\n",
    "column_names = [\"image_path\", \"frame_id\", \"anomaly_types\", \"identification\"]\n",
    "df = df.merge(labels[column_names], on=\"image_path\", how=\"left\")\n",
    "\n",
    "df[\"anomaly_types\"].replace(\"good\", \"nominal\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby([\"anomaly_types\"])[f\"{prefix_scores}anomaly_score\"].apply(list)\n",
    "labels_groups = groups.index.tolist()\n",
    "# Put nominal in first position to plot it in blue\n",
    "labels_groups.remove(\"nominal\")\n",
    "labels_groups.insert(0, \"nominal\")\n",
    "groups_values = groups[labels_groups].tolist()\n",
    "metric_prefix = f\"{split}_image_\"\n",
    "metrics_ = metrics[[f\"{metric_prefix}{m}\" for m in metrics_lst]].tolist()\n",
    "metrics_dict = {k: [v] for k, v in zip(metrics_lst, metrics_)}\n",
    "metrics_idx = [\"Global\"]\n",
    "# Compute score by including only one type of anomaly\n",
    "for anomaly_type in labels_groups[1:]:\n",
    "    metrics_idx.append(anomaly_type)\n",
    "    y_pred = groups[\"nominal\"] + groups[anomaly_type]\n",
    "    y_true = [0] * len(groups[\"nominal\"]) + [1] * len(groups[anomaly_type])\n",
    "    scores = compute_metrics(y_true, y_pred, threshold, metrics_lst)\n",
    "    for metric_name, score in zip(metrics_lst, scores):\n",
    "        metrics_dict[metric_name].append(score.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8139ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot anomaly score distribution per anomaly type\n",
    "print(title)\n",
    "plot_histogram(bins, groups_values, labels_groups, threshold, \"\", 16, colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befdece0-f8a2-4272-8c81-06054de2ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in anomaly score distribution per anomaly type anomalous images\n",
    "labels_groups_without_nominal = labels_groups.copy()\n",
    "labels_groups_without_nominal.remove(\"nominal\")\n",
    "groups_values_without_nominal = groups[labels_groups_without_nominal].tolist()\n",
    "plot_histogram(bins, groups_values_without_nominal, labels_groups_without_nominal, threshold, \"\", 16, colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebea808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print scores\n",
    "pd.DataFrame(metrics_dict, index=metrics_idx).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4052f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "predicted = []\n",
    "for idx, group_name in enumerate(labels_groups):\n",
    "    actual += [idx] * len(groups_values[idx])\n",
    "    anomalous_label = len(labels_groups) if group_name == \"nominal\" else idx\n",
    "    predicted_ = np.where(np.array(groups_values[idx]) >= threshold, anomalous_label, 0)\n",
    "    predicted += list(predicted_)\n",
    "actual = np.array(actual)\n",
    "predicted = np.array(predicted)\n",
    "labels_groups.append(\"anomalous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18c488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nominal images that are badly predicted will appear in the Anomalous category\n",
    "print(title)\n",
    "plot_confusion_matrix(predicted, actual, labels_groups, \"\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baac5b5",
   "metadata": {},
   "source": [
    "# Per anomaly IDs (HQ dataset only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"identification\"] = df[\"identification\"].fillna(\"nominal\")\n",
    "df[\"prediction\"] = (df[f\"{prefix_scores}anomaly_score\"] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = df[[\"image_path\", \"identification\", \"target\", \"prediction\"]].drop_duplicates()\n",
    "df_groups = df_ids.groupby([\"identification\", \"prediction\"]).size()\n",
    "anomaly_groups = df_groups.unstack().iloc[:-1]\n",
    "anomaly_groups.plot(figsize=(15, 7), kind=\"bar\", stacked=True, xlabel=\"Identification\", ylabel=\"Count\")\n",
    "plt.minorticks_on()\n",
    "plt.grid(axis=\"y\", which=\"major\", linestyle=\"-\", linewidth=\"0.5\", color=\"grey\")\n",
    "plt.grid(axis=\"y\", which=\"minor\", linestyle=\":\", linewidth=\"0.5\", color=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0589405",
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_groups = df_groups.unstack().iloc[-1]\n",
    "nominal_groups.plot(figsize=(15, 7), kind=\"bar\", stacked=True, xlabel=\"Prediction nominal images\", ylabel=\"Count\")\n",
    "plt.minorticks_on()\n",
    "plt.grid(axis=\"y\", which=\"major\", linestyle=\"-\", linewidth=\"0.5\", color=\"grey\")\n",
    "plt.grid(axis=\"y\", which=\"minor\", linestyle=\":\", linewidth=\"0.5\", color=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673121fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = df[[\"image_path\", \"identification\", \"target\", f\"{prefix_scores}anomaly_score\"]].drop_duplicates()\n",
    "df_ids_abn = df_ids[df_ids[\"identification\"] != \"nominal\"]\n",
    "df_ids_norm = df_ids[df_ids[\"identification\"] == \"nominal\"][[\"identification\", f\"{prefix_scores}anomaly_score\"]]\n",
    "# An anomaly is considered well predicted if found in at least one frame\n",
    "df_ids_abn = df_ids_abn.groupby([\"identification\"])[f\"{prefix_scores}anomaly_score\"].max().reset_index()\n",
    "pred_ids_level = pd.concat([df_ids_abn, df_ids_norm], axis=0)\n",
    "pred_ids_level[\"target\"] = (pred_ids_level[\"identification\"] != \"nominal\").astype(int)\n",
    "\n",
    "scores = compute_metrics(\n",
    "    pred_ids_level[\"target\"], pred_ids_level[f\"{prefix_scores}anomaly_score\"], threshold, metrics_lst\n",
    ")\n",
    "metrics_idx.insert(1, \"Per unique anomaly\")\n",
    "for metric_name, score in zip(metrics_lst, scores):\n",
    "    metrics_dict[metric_name].insert(1, score.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print scores\n",
    "metrics_df = pd.DataFrame(metrics_dict, index=metrics_idx).T\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc6304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global scores with duplicates\n",
    "predicted = df[f\"{prefix_scores}anomaly_score\"].to_numpy()\n",
    "actual = df[\"target\"].to_numpy()\n",
    "plot_confusion_matrix(np.where(predicted >= threshold, 1, 0), actual, label_groups, title, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f40c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Precision-Recall curve with duplicate (image level)\n",
    "plot_precision_recall_curve(\n",
    "    actual,\n",
    "    predicted,\n",
    "    None,\n",
    "    None,\n",
    "    threshold,\n",
    "    recall_level=\"image\",\n",
    "    precision_level=\"image\",\n",
    "    title=\"\",  # f\"{split.capitalize()} set\\nPrecision-Recall curve\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1255b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Precision-Recall curve with duplicate (ID level)\n",
    "actual_id = pred_ids_level[\"target\"]\n",
    "predicted_id = pred_ids_level[f\"{prefix_scores}anomaly_score\"]\n",
    "plot_precision_recall_curve(\n",
    "    None,\n",
    "    None,\n",
    "    actual_id,\n",
    "    predicted_id,\n",
    "    threshold,\n",
    "    recall_level=\"ID\",\n",
    "    precision_level=\"ID\",\n",
    "    title=\"\",  # f\"{split.capitalize()} set\\nPrecision-Recall curve per unique anomaly\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34df0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Precision-Recall curve with duplicate (image level precision vs ID level recall)\n",
    "plot_precision_recall_curve(\n",
    "    actual,\n",
    "    predicted,\n",
    "    actual_id,\n",
    "    predicted_id,\n",
    "    threshold,\n",
    "    recall_level=\"ID\",\n",
    "    precision_level=\"image\",\n",
    "    title=\"\",  # f\"{split.capitalize()} set\\nPrecision-Recall curve per unique anomaly\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d2ae2",
   "metadata": {},
   "source": [
    "### Information about anomaly ids and their connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"identification\", \"anomaly_types\"])[\"frame_id\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "anomalous_img_labels = df[df[\"target\"] == 1].copy()\n",
    "anomalous_img_paths = anomalous_img_labels[\"image_path\"].unique()\n",
    "for img in sorted(anomalous_img_paths):\n",
    "    img_info = anomalous_img_labels[anomalous_img_labels[\"image_path\"] == img]\n",
    "    identification = img_info[\"identification\"].tolist()\n",
    "    lists.append(identification)\n",
    "# A graph is used to connect the anomalies that appear in a single image.\n",
    "# That way, we make sure that we have no leak between the splits.\n",
    "anomaly_graph = networkx.Graph()\n",
    "for sub_list in lists:\n",
    "    for edge in combinations(sub_list, r=2):\n",
    "        anomaly_graph.add_edge(*edge)\n",
    "connected_anomalies = list(networkx.connected_components(anomaly_graph))\n",
    "connected_anomalies = [i for i in connected_anomalies if len(i) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060f0bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get wrongly predicted images\n",
    "df_wrong = df[df[\"target\"] != df[\"prediction\"]]\n",
    "groups = df_wrong.groupby([\"identification\"])[\"image_path\"].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f19581",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412cc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in groups.index:\n",
    "    print(idx)\n",
    "    for path in groups.loc[idx]:\n",
    "        print(path)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wrongly predicted images for a given anomaly ID or for nominal images\n",
    "\n",
    "# Uncomment idx variable and change the anomaly ID to plot it's wrongly predicted images\n",
    "# Or change idx variable to \"nominal\" to plot wrongly predicted nominal images\n",
    "# idx = \"001_00\"\n",
    "paths = groups.loc[idx]\n",
    "\n",
    "# TODO: see if we can sort by scores\n",
    "if idx == \"nominal\":\n",
    "    fig, axs = plt.subplots(int(len(paths) / 4) + 1, 4, figsize=(3.5 * 4, 3.5 * int(len(paths) / 4)))\n",
    "else:\n",
    "    fig, axs = plt.subplots(len(paths), 2, figsize=(3.5 * 2, 3.5 * len(paths)))\n",
    "fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "axs = axs.ravel()\n",
    "\n",
    "i = 0\n",
    "for f in paths:\n",
    "    # Image\n",
    "    fname = os.path.join(data_folder, f)\n",
    "    img = Image.open(fname)\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.asarray(img)\n",
    "    axs[i].imshow(img)\n",
    "    axs[i].set_title(f, fontsize=8)\n",
    "    i += 1\n",
    "    if idx != \"nominal\":\n",
    "        # Mask\n",
    "        fname = fname.replace(\"images\", \"masks\")\n",
    "        img = Image.open(fname)\n",
    "        img = img.resize((224, 224))\n",
    "        img = np.asarray(img)\n",
    "        axs[i].imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axs[i].set_title(f.replace(\"images\", \"masks\"), fontsize=8)\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
